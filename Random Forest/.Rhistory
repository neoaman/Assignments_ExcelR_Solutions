train <- sample(x = 1:nrow(iris),size = round(nrow(iris)*.3),replace = F)
train_df <- iris[train,]
test_df <- iris[-train,]
test_df
library(e1071)
mmodel1 <- naiveBayes(Species~., data=train_df)
mmodel1
pred_1 <- predict(model1,test_df[,-5])
pred_1 <- predict(model1,test_df)
mmodel1 <- naiveBayes(Species~., data=train_df)
pred_1 <- predict(mmodel1,test_df[,-5])
pred_1
table(pred_1)
log(0.5,2)
- ((0.5 * log(0.5,2)) + (0.5 * log(0.5,2) ))
(0.5 * log(0.5,2))
a = c(5,5)
prop.table(a)
b = prop.table(a)
-sum(p*log(p,2))
-sum(b*log(b,2))
ectropy <- function(a){
b = prop.table(a)
print(-sum(b*log(b,2)))
}
entropy(c(10,0))
entropy(c(10,1))
ectropy(c(10,1))
ectropy(c(5,5))
ectropy(c(6,4))
ectropy(c(6,4,6))
ectropy <- function(a){
b = prop.table(a)
print(-sum(b*log(b,2)))
}
ectropy(c(6,4,6))
ectropy(c(6,6))
ectropy(c(6,6,6))
prpo.table(c(5,5,5))
prop.table(c(5,5,5))
ectropy(c(5,9))
ectropy(c(5,9,5))
ectropy(c(5,5,5))
ectropy(c(5,5,5))
ectropy(c(3,1))
ectropy(c(3,1))
ectropy(c(4,2))
ectropy(c(2,2))
data(iris)
library(tree)
install.packages("tree")
library(tree)
tree1 <- tree(iris$Species~.,data = iris)
plot(tree1)
plot(tree1,type = "b")
text(tree1)
plot(tree1)
text(tree1)
plot(tree1)
text(tree1)
plot(tree1)
text(tree1)
text(tree1,col="red")
text(tree1,col=1:5)
plot(tree1,lwd=5)
text(tree1,col=1:5)
plot(tree1,lwd=5,lty=2)
text(tree1,col=1:5)
plot(tree1,lwd=5,lty=2,col='forestgreen')
text(tree1,col=1:5)
install.packages("survival")
library('survival')
library("survminer")
install.packages(c("survival","survminer"))
install.packages("survminer")
data("diabetes")
diabetic
diabetic
survfit(Surv(diabetic$age,diabetic$status)~diabetic$eye)
summary(survfit(Surv(diabetic$age,diabetic$status)~diabetic$eye))
ls(char="v")
ls("V")
A <- "AMAN"
ls()
setwd("D:\\STUDY PROCESS\\Excelr\\Assignments\\Pending\\NN")
normalize_dummy <- function(x){
col <- ncol(x)
row <- nrow(x)
y <- 1:nrow(x)
for (i in 1:col){
if(class(x[,i])=="numeric" | class(x[,i])=="integer")
{
minx <- min(x[,i])
maxx <- max(x[,i])
for(j in 1:row)
{
x[j,i] <- ifelse((x[j,i] - minx) != 0,yes =((x[j,i] - minx) / (maxx - minx)),no = 0)
}
}
}
f <- c()
for(i in 1:ncol(x)){
if(class(x[,i])=="factor"){
dummies <- data.frame(dummies::dummy(x[,i]))
y <- data.frame(y,dummies)
f <- c(f,i)
}
else{
next
}
}
if(is.null(f)){
output <- x
}
else{output <- data.frame(x[,-f],y[,-1])}
return(output)
}
denormalize <- function(x,max,min){
denormalize <- ((x*(max-min)) + min)
return(denormalize)
}
#install.packages(c("neuralnet","nnet"))
library(nnet);library(neuralnet)
# Question  no 1 ----
"Build a Neural Network model for 50_startups data to predict profit "
statups <- read.csv("50_Startups (1).csv")
setwd("D:\\STUDY PROCESS\\Excelr\\Assignments\\Pending\\NN")
setwd("D:\\STUDY PROCESS\\Excelr\\Assignments\\Pending\\NN_Issues")
setwd("D:\\STUDY PROCESS\\Excelr\\Assignments\\Pending\\NN_ Issues")
setwd("D:\\STUDY PROCESS\\Excelr\\Assignments\\Decission Tree")
#install.packages("randomForest")
library(randomForest)
normalize_dummy <- function(x){
col <- ncol(x)
row <- nrow(x)
y <- 1:nrow(x)
for (i in 1:col){
if(class(x[,i])=="numeric" | class(x[,i])=="integer")
{
minx <- min(x[,i])
maxx <- max(x[,i])
for(j in 1:row)
{
x[j,i] <- ifelse((x[j,i] - minx) != 0,yes =((x[j,i] - minx) / (maxx - minx)),no = 0)
}
}
}
f <- c()
for(i in 1:ncol(x)){
if(class(x[,i])=="factor"){
dummies <- data.frame(dummies::dummy(x[,i]))
y <- data.frame(y,dummies)
f <- c(f,i)
}
else{
next
}
}
if(is.null(f)){
output <- x
}
else{output <- data.frame(x[,-f],y[,-1])}
return(output)
}
company <- read.csv("Company_Data.csv")
head(company)
nrow(company)
str(company)
boxplot(company)$out # 9 data point as outliers
boxplot(scale(company[,c(1:6,8,9)])) # Sales, CompPrice and Price contains outlier.
# Outlier treatment
boxplot(company)$out
outlie1 <- which(company$Sales >= min(boxplot(company$Sales)$out))#317,377
outlie2 <- which(company$CompPrice == max(boxplot(company$CompPrice)$out)
|company$CompPrice == min(boxplot(company$CompPrice)$out) )#43,311
outlie3 <- which(company$Price <= 53 | company$Price >= 185)
outlier <- c(outlie1,outlie2,outlie3)
company_o <- company[-outlier,]
boxplot(company_o)$out
boxplot(company_o$Price)$out
company_final <- company_o[company_o$Price >55,]
nrow(company_final)
SaleC <- ifelse(company_final$Sales > 8.5,"High","Low")
df_c <- data.frame(company_final[,-1],SaleC)
# Presence of missing values
colSums(is.na(df_c)) # No missing data in my data set
# Train Test Split of Data.
set.seed(101);splitC <- sample(nrow(company_final),nrow(company_final)*.7,F)
trainC <- df_c[splitC,]
testC <- df_c[-splitC,]
trainC_n <- normalize_dummy(trainC[,-11])
colnames(trainC_n) <- cn
cn
cn <- c("CompPrice","Income","Advertising","Population","Price","Age","Education","CBad","CGood","CMedium","CNo","CYes","CNo.1","CYes.1")
colnames(trainC_n) <- cn
testC_n <- normalize_dummy(testC[,-11])
testC_n
# Model Building Model no 1
set.seed(101);modelC1 <- randomForest(trainC$SaleC~.,data = trainC[,-11])
# Model Building Model no 1
set.seed(101);modelC1 <- randomForest(trainC$SaleC~.,data = trainC[,-11])
summary(modelC1)
predC1 <- predict(modelC1,testC)
table(Actual=testC$SaleC,Predicted=predC1)
mean(testC$SaleC==predC1) # 82.9% accuracy
plot(modelC1)
varImpPlot(modelC1, pch = 20, main = "Importance of Variables")
# Model 2 Building with normalised values
set.seed(101);modelC2 <- randomForest(trainC$SaleC~.,data = trainC_n)
summary(modelC2)
predC2 <- predict(modelC2,testC_n)
predC2 <- predict(modelC2,testC_n)
summary(modelC2)
predC2 <- predict(modelC2,testC_n)
library(cbad)
predC2 <- predict(modelC2,testC_n)
predC2 <- predict(modelC2,testC_n)
predC2
summary(modelC2)
testC_n
modelC2
predict
predC2 <- predict(modelC2,testC_n)
predC2 <- predict(object = modelC2,newdata = testC_n)
install.packages("randomForest")
install.packages("randomForest")
setwd("D:\\STUDY PROCESS\\Excelr\\Assignments\\Decission Tree")
#install.packages("randomForest")
library(randomForest)
normalize_dummy <- function(x){
col <- ncol(x)
row <- nrow(x)
y <- 1:nrow(x)
for (i in 1:col){
if(class(x[,i])=="numeric" | class(x[,i])=="integer")
{
minx <- min(x[,i])
maxx <- max(x[,i])
for(j in 1:row)
{
x[j,i] <- ifelse((x[j,i] - minx) != 0,yes =((x[j,i] - minx) / (maxx - minx)),no = 0)
}
}
}
f <- c()
for(i in 1:ncol(x)){
if(class(x[,i])=="factor"){
dummies <- data.frame(dummies::dummy(x[,i]))
y <- data.frame(y,dummies)
f <- c(f,i)
}
else{
next
}
}
if(is.null(f)){
output <- x
}
else{output <- data.frame(x[,-f],y[,-1])}
return(output)
}
company <- read.csv("Company_Data.csv")
head(company)
nrow(company)
str(company)
boxplot(company)$out # 9 data point as outliers
boxplot(scale(company[,c(1:6,8,9)])) # Sales, CompPrice and Price contains outlier.
# Outlier treatment
boxplot(company)$out
outlie1 <- which(company$Sales >= min(boxplot(company$Sales)$out))#317,377
outlie2 <- which(company$CompPrice == max(boxplot(company$CompPrice)$out)
|company$CompPrice == min(boxplot(company$CompPrice)$out) )#43,311
outlie3 <- which(company$Price <= 53 | company$Price >= 185)
outlier <- c(outlie1,outlie2,outlie3)
company_o <- company[-outlier,]
boxplot(company_o)$out
boxplot(company_o$Price)$out
company_final <- company_o[company_o$Price >55,]
nrow(company_final)
SaleC <- ifelse(company_final$Sales > 8.5,"High","Low")
df_c <- data.frame(company_final[,-1],SaleC)
# Presence of missing values
colSums(is.na(df_c)) # No missing data in my data set
# Train Test Split of Data.
set.seed(101);splitC <- sample(nrow(company_final),nrow(company_final)*.7,F)
trainC <- df_c[splitC,]
testC <- df_c[-splitC,]
trainC_n <- normalize_dummy(trainC[,-11])
cn <- c("CompPrice","Income","Advertising","Population","Price","Age","Education","CBad","CGood","CMedium","CNo","CYes","CNo.1","CYes.1")
colnames(trainC_n) <- cn
testC_n <- normalize_dummy(testC[,-11])
colnames(testC_n) <- cn
# Model Building Model no 1
set.seed(101);modelC1 <- randomForest(trainC$SaleC~.,data = trainC[,-11])
summary(modelC1)
predC1 <- predict(modelC1,testC)
table(Actual=testC$SaleC,Predicted=predC1)
mean(testC$SaleC==predC1) # 82.9% accuracy
plot(modelC1)
varImpPlot(modelC1, pch = 20, main = "Importance of Variables")
# Model 2 Building with normalised values
set.seed(101);modelC2 <- randomForest(trainC$SaleC~.,data = trainC_n)
summary(modelC2)
predC2 <- predict(object = modelC2,newdata = testC_n)
predC2
table(Actual=testC$SaleC,Predicted=predC2)
mean(testC$SaleC==predC2) # 79.487% accuracy
plot(modelC2)
# Tuning the random Forest
set.seed(101);tune <- tuneRF(trainC[,-11], trainC[,11], stepFactor = 0.5, plot = TRUE, ntreeTry = 400,
trace = TRUE, improve = 0.05)
# Model 3
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 400, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 400, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 400, mtry = 3)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 500, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 700, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 1000, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 10, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 100, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 200, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 300, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 400, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 500, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
# Model 4
set.seed(101);model3C <- randomForest(trainC$SaleC~.,data = trainC[,-11], ntree = 800, mtry = 3, importance = TRUE,proximity = TRUE)
predC3 <- predict(model3C,testC[,-11])
table(Actual=testC$SaleC,Predicted=predC3)
mean(testC$SaleC==predC3) # 84.6%
df = read.csv("Fraud_check.csv")
df = read.csv("Fraud_check.csv")
df
head(df)
GR <- ifelse(df$Taxable.Income>30000,"Risky","Good")
Fraud <- data.frame(df[,-3],GR)
Fraud
boxplot(Fraud)
boxplot(Fraud$GR)
barplot(Fraud$GR)
Fraud$GR
barplot(table(Fraud$GR))
# Encoding Risky and Good
GR <- ifelse(df$Taxable.Income<30000,"Risky","Good")
Fraud <- data.frame(df[,-3],GR)
boxplot(Fraud) #no sign of outliers in the data
barplot(table(Fraud$GR))
str(Fraud)
colSums(is.na(Fraud))
# Train Test Splitting
set.seed(101);splitF <- sample(nrow(Fraud),nrow(Fraud)*.7,F)
Train_F <- Fraud[splitF,]
Test_F <- Fraud[-splitF,]
Train_F
Test_F
Train_F[,-6]
ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
predF1
mean(Test_F$GR==predF1)
set.seed(101);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(101);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(105);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(2);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(1);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(5);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(10);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(16);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(20);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
set.seed(101);ModelF1 <- randomForest(Train_F$GR~.,data = Train_F[,-6])
predF1 <- predict(ModelF1,Test_F[,-6])
mean(Test_F$GR==predF1) # accuracy is
table(Actual=Test_F$GR,Predicted=predF1)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 30,mtry = 3,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 300,mtry = 3,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 4000,mtry = 3,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 4000,mtry = 6,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 6,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 5,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
Train_F[,6]
# Tuning of random forest
set.seed(101);tune <- tuneRF(Train_F[,-6], Train_F[,6], stepFactor = 0.5, plot = TRUE, ntreeTry = 400,
trace = TRUE, improve = 0.05)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 0,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 1,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 4,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 2,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 1,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
# Tuning of random forest
set.seed(101);tune <- tuneRF(Train_F[,-6], Train_F[,6], stepFactor = 0.5, plot = TRUE, ntreeTry = 400,
trace = TRUE, improve = 0.5)
# Tuning of random forest
set.seed(101);tune <- tuneRF(Train_F[,-6], Train_F[,6], stepFactor = 0.6, plot = TRUE, ntreeTry = 400,
trace = TRUE, improve = 0.5)
# Tuning of random forest
set.seed(101);tune <- tuneRF(Train_F[,-6], Train_F[,6], stepFactor = 0.5, plot = TRUE, ntreeTry = 4000,
trace = TRUE, improve = 0.5)
# Tuning of random forest
set.seed(101);tune <- tuneRF(Train_F[,-6], Train_F[,6], stepFactor = 0.5, plot = TRUE, ntreeTry = 300,
trace = TRUE, improve = 0.5)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 1,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
table(Actual = Test_F$GR,Predicted=predF2)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 2,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.8166667
table(Actual = Test_F$GR,Predicted=predF2)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 1,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.8166667
table(Actual = Test_F$GR,Predicted=predF2)
table(Actual = Test_F$GR,Predicted=predF2)
plot(ModelF1)
plot(ModelF2)
plot(ModelF2)
set.seed(101);ModelF2 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 5,data=Train_F)
predF2 <- predict(ModelF2,Test_F[,-6])
mean(Test_F$GR==predF2) #0.73333
plot(ModelF2)
# We are getting least error when Mtry is 1
set.seed(101);ModelF3 <- randomForest(Train_F$GR~.,ntree = 400,mtry = 1,data=Train_F)
predF3 <- predict(ModelF3,Test_F[,-6])
mean(Test_F$GR==predF3) #0.8166667
table(Actual = Test_F$GR,Predicted=predF3)
plot(ModelF3)
